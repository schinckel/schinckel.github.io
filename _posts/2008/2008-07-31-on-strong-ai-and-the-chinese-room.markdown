--- 
wordpress_id: 1525
layout: post
title: On Strong AI and the Chinese Room.
time: "18:44:15"
date: 2008-07-31 18:44:15
tags: 
- general
- ai
wordpress_url: http://schinckel.net/2008/07/31/on-strong-ai-and-the-chinese-room/
---
This is a post taken out of context I made to a discussion group in my AI subject. (Which another Matt and I have decided they falsely advertised, and should have called "Expert Systems"). It's a bit vague in a couple of places, and I will probably come back to this topic at some stage and write a clearer explanation of what I mean. But this is here for now.

I did some thinking about the thought experiment where a guy sits in a room translating English into Chinese, and how "He will probably learn some characters over time.", and how this is not the same as a machine.  
  
I think it _is_ the same. If a machine is able to recognise a word/character, that is still the same as the man learning it, rather than just memorising it. (I'd actually counter that memorising meanings and symbols is still a type of learning, and I come from an educational background, so I do know a little about learning).  
  
But I want to push even further. A human isn't the same as a translating program because it can learn new information that wasn't there when the program was written. If a program is able to incorporate new facts, develop new pathways, and perhaps even rewrite it's own program, then this is a much closer analogy to what we define is learning.  
  
There are system out there that allow for dynamic reprogramming (I think some derivatives of Smalltalk are pretty good at this), and many systems that allow for dynamic alteration of code (perhaps by an outside source). Even the OLPC project is based on a system which can be changed while it is running.  
  
Our brains are a machine that can alter it's physical structure in response to the environment - indeed that is how we learn - and the pathways that are used often eventually end up working better than those that are used infrequently. A program could work the same way. Evolutionary programming is another example - an algorithm can be seeded, and then a variety of mutations are generated, and an "overseer" selects the mutations which result in a better algorithm.  
  
I can't provide any hard quotes, but I know this has been used to some extent to develop novel programs.  


I know this is verging on Strong AI, which Darius says is a no-no, but consider this post as having taken place in a pub or cafe. In fact, I'm off to the pub now.
